{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenkao/miniconda3/envs/music-hw3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import os\n",
    "import miditok\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.pytorch_data import DataCollator, DatasetMIDI\n",
    "from torch.utils.data import DataLoader\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "from tqdm import tqdm\n",
    "from midi_player import MIDIPlayer\n",
    "from main import ModelConfig, checkpoint_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint checkpoints/cp_82.pt\n",
      "model parameters: 38,532,608\n"
     ]
    }
   ],
   "source": [
    "tkn_config = TokenizerConfig(\n",
    "    use_tempos=True,\n",
    "    use_pitchdrum_tokens=False,\n",
    "    beat_res={(0, 4): 16, (4, 12): 8},\n",
    ")\n",
    "tokenizer = REMI(tkn_config)\n",
    "config = ModelConfig(\n",
    "    device=\"cpu\",\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_embd=512,\n",
    "    n_head=8,\n",
    "    n_layers=12,\n",
    "    batch_size=8,\n",
    "    max_seq_length=1024,\n",
    ")\n",
    "\n",
    "gpt_config = GPT2Config(\n",
    "    vocab_size=config.vocab_size,\n",
    "    n_positions=config.max_seq_length,\n",
    "    n_embd=config.n_embd,\n",
    "    n_layer=config.n_layers,\n",
    "    n_head=config.n_head,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "model = GPT2LMHeadModel(gpt_config)\n",
    "model.generation_config.pad_token_id = tokenizer[\"PAD_None\"]\n",
    "model.to(config.device)\n",
    "checkpoint_load(\"checkpoints/cp_82.pt\", model, config)\n",
    "model.eval()\n",
    "\n",
    "print(f\"model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating tokens:   0%|          | 1/3072 [00:00<01:08, 44.77token/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample_size = 2\n",
    "tokens = torch.tensor(\n",
    "    [[tokenizer.vocab[\"Bar_None\"]]] * sample_size,\n",
    "    device=config.device,\n",
    ") # (batch_n, seq_n)\n",
    "\n",
    "with tqdm(total=config.max_sample_length, desc=\"Generating tokens\", unit=\"token\") as pbar:\n",
    "    while tokens.size(1) < config.max_sample_length:\n",
    "        # Generate one token at a time\n",
    "        input_context = tokens[:, -(config.max_seq_length - 1):]\n",
    "        output = model.generate(\n",
    "            input_context,\n",
    "            attention_mask=torch.ones(input_context.shape, device=config.device),\n",
    "            max_length=input_context.size(1) + 1,\n",
    "            do_sample=True,\n",
    "        )\n",
    "        new_token = output[:, -1:]\n",
    "        tokens = torch.cat((tokens, new_token), dim=1)\n",
    "        pbar.update(1)\n",
    "\n",
    "        # check if all batch has ended\n",
    "        all_end = (tokens == tokenizer[\"EOS_None\"]).any(dim=1).all() \n",
    "        if all_end:\n",
    "            break\n",
    "\n",
    "# print(\"sample token len\", tokens.size(1))\n",
    "# # tokens = tokens.cpu()\n",
    "# # tokenizer.decode(tokens)\n",
    "# # score = tokenizer.decode(tokens)\n",
    "# # score.dump_midi(save_path)\n",
    "# # wandb.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
