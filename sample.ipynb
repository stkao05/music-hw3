{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenkao/miniconda3/envs/music-hw3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('musdr')\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import os\n",
    "import miditok\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.pytorch_data import DataCollator, DatasetMIDI\n",
    "from torch.utils.data import DataLoader\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GenerationConfig\n",
    "from tqdm import tqdm\n",
    "from midi_player import MIDIPlayer\n",
    "from main import ModelConfig, checkpoint_load\n",
    "from eval_metrics import eval_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint checkpoints/cp_82.pt\n",
      "model parameters: 38,532,608\n"
     ]
    }
   ],
   "source": [
    "tkn_config = TokenizerConfig(\n",
    "    use_tempos=True,\n",
    "    use_pitchdrum_tokens=False,\n",
    "    beat_res={(0, 4): 16, (4, 12): 8},\n",
    ")\n",
    "tokenizer = REMI(tkn_config)\n",
    "config = ModelConfig(\n",
    "    device=\"cpu\",\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_embd=512,\n",
    "    n_head=8,\n",
    "    n_layers=12,\n",
    "    batch_size=8,\n",
    "    max_seq_length=1024,\n",
    ")\n",
    "\n",
    "gpt_config = GPT2Config(\n",
    "    vocab_size=config.vocab_size,\n",
    "    n_positions=config.max_seq_length,\n",
    "    n_embd=config.n_embd,\n",
    "    n_layer=config.n_layers,\n",
    "    n_head=config.n_head,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "model = GPT2LMHeadModel(gpt_config)\n",
    "model.generation_config.pad_token_id = tokenizer[\"PAD_None\"]\n",
    "model.to(config.device)\n",
    "checkpoint_load(\"checkpoints/cp_82.pt\", model, config)\n",
    "model.eval()\n",
    "\n",
    "print(f\"model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(gen_config: GenerationConfig):\n",
    "    sample_dir = Path(\"samples_final\")\n",
    "    sample_size = 2\n",
    "    config.max_sample_length = 100\n",
    "\n",
    "    tokens = torch.tensor(\n",
    "        [[tokenizer.vocab[\"Bar_None\"]]] * sample_size,\n",
    "        device=config.device,\n",
    "    ) # (batch_n, seq_n)\n",
    "\n",
    "    with tqdm(total=config.max_sample_length, desc=\"Generating tokens\", unit=\"token\") as pbar:\n",
    "        while tokens.size(1) < config.max_sample_length:\n",
    "            # Generate one token at a time\n",
    "            input_context = tokens[:, -(config.max_seq_length - 1):]\n",
    "            output = model.generate(\n",
    "                input_context,\n",
    "                attention_mask=torch.ones(input_context.shape, device=config.device),\n",
    "                generation_config=gen_config,\n",
    "                max_length=input_context.size(1) + 1,\n",
    "                do_sample=True\n",
    "            )\n",
    "            new_token = output[:, -1:]\n",
    "            tokens = torch.cat((tokens, new_token), dim=1)\n",
    "            pbar.update(1)\n",
    "\n",
    "            # check if all batch has ended\n",
    "            all_end = (tokens == tokenizer[\"EOS_None\"]).any(dim=1).all() \n",
    "            if all_end:\n",
    "                break\n",
    "\n",
    "    # print(\"sample token len\", tokens.size(1))\n",
    "    tokens = tokens.cpu()\n",
    "    for i in range(tokens.size(0)):\n",
    "        score = tokenizer.decode(tokens[i:i+1, :])\n",
    "        score.dump_midi(sample_dir / f\"{i}.mid\")\n",
    "\n",
    "    print(\"evaluating\", sample_dir)\n",
    "    eval_result = eval_dir(sample_dir, tokenizer, result_path=f\"{sample_dir.name}.csv\")\n",
    "    print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating tokens:  99%|█████████▉| 99/100 [00:03<00:00, 30.16token/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating samples_final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 96.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] window_size: 4 too large for the piece, falling back to #(bars) of the piece.\n",
      "{'piece_name': ['0.mid', '1.mid'], 'H1': [np.float64(2.390062372851439), np.float64(1.6480447857883704)], 'H4': [np.float64(2.5535088547976783), np.float64(2.567497103431931)], 'GS': [np.float64(0.796875), np.float64(0.93125)]}\n",
      "{'H1': 2.0190535793199045, 'H4': 2.560502979114805, 'GS': 0.8640625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample(GenerationConfig())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
